{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "variational_autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-oTgkQUJ4vkd",
        "RBAJMvvw4imV",
        "B08x1_kD4jGB"
      ],
      "authorship_tag": "ABX9TyPeq3hWc7WVfu79UhqSaTjv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sal4321/Survival-Predicition-using-Autoencoder-and-AFT-/blob/main/variational_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id8QsOkTU1jM"
      },
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Reshape, Flatten, Input, GaussianNoise,BatchNormalization\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.layers import GaussianNoise\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras import Sequential, Model\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from lifelines.utils import concordance_index\n",
        "\n",
        "tfd = tfp.distributions\n",
        "tfpl = tfp.layers\n",
        "tfb = tfp.bijectors"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BzQ2fTeHNkD",
        "outputId": "6175958e-90d0-4725-835e-f5eddb13efcb"
      },
      "source": [
        "pip install lifelines"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lifelines\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/ba/d010b22c8bcdfe3bbba753bd976f5deddfa4ec1c842b991579e9c2c3cd61/lifelines-0.26.0-py3-none-any.whl (348kB)\n",
            "\r\u001b[K     |█                               | 10kB 15.4MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 20.2MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30kB 19.5MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40kB 15.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 51kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 71kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 92kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 102kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 112kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 122kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 133kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 143kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 153kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 174kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 184kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 194kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 204kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 215kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 225kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 235kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 245kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 256kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 266kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 276kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 286kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 296kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 307kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 317kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 327kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 337kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 348kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 358kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.7/dist-packages (from lifelines) (3.2.2)\n",
            "Collecting autograd-gamma>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/85/ae/7f2031ea76140444b2453fa139041e5afd4a09fc5300cfefeb1103291f80/autograd-gamma-0.5.0.tar.gz\n",
            "Collecting formulaic<0.3,>=0.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/64/6702b5cadc89ece93af2e01996504f3a895196354a35713e2ef22f089d3e/formulaic-0.2.3-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from lifelines) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from lifelines) (1.1.5)\n",
            "Requirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from lifelines) (1.3)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from lifelines) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines) (2.4.7)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.7/dist-packages (from formulaic<0.3,>=0.2.2->lifelines) (1.12.1)\n",
            "Collecting interface-meta>=1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/71/31/5e474208f5df9012ebecfaa23884b14f93671ea4f4f6d468eb096b73e499/interface_meta-1.2.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from formulaic<0.3,>=0.2.2->lifelines) (0.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->lifelines) (2018.9)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->lifelines) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.0->lifelines) (1.15.0)\n",
            "Building wheels for collected packages: autograd-gamma\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-cp37-none-any.whl size=4050 sha256=54059f57e773fe5923304dbb8dd72d98150c40292ac77556c9ad482befad26ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/68/dc/91321c55fba449755524481854f5be70d41912b8f886f908bb\n",
            "Successfully built autograd-gamma\n",
            "Installing collected packages: autograd-gamma, interface-meta, formulaic, lifelines\n",
            "Successfully installed autograd-gamma-0.5.0 formulaic-0.2.3 interface-meta-1.2.3 lifelines-0.26.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEiCaHt6kLJQ",
        "outputId": "64eecb0d-bf75-4b0c-d51f-c5657f524178"
      },
      "source": [
        "!pip install lifelines"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lifelines in /usr/local/lib/python3.7/dist-packages (0.25.11)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.7/dist-packages (from lifelines) (3.2.2)\n",
            "Requirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from lifelines) (1.3)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from lifelines) (1.4.1)\n",
            "Requirement already satisfied: formulaic<0.3,>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from lifelines) (0.2.3)\n",
            "Requirement already satisfied: autograd-gamma>=0.3 in /usr/local/lib/python3.7/dist-packages (from lifelines) (0.5.0)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from lifelines) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from lifelines) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines) (0.10.0)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->lifelines) (0.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.7/dist-packages (from formulaic<0.3,>=0.2.2->lifelines) (1.12.1)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from formulaic<0.3,>=0.2.2->lifelines) (0.8.1)\n",
            "Requirement already satisfied: interface-meta>=1.2 in /usr/local/lib/python3.7/dist-packages (from formulaic<0.3,>=0.2.2->lifelines) (1.2.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->lifelines) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.0->lifelines) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_5GsIMsUhAQ"
      },
      "source": [
        "#load the clinical_data\n",
        "clinical_data=pd.read_csv(\"out.csv\")    "
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "rt54e8bZU5QD",
        "outputId": "85877105-a5cf-40ed-9a5d-6dcb261fde72"
      },
      "source": [
        "clinical_data.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attrib_name</th>\n",
              "      <th>years_to_birth</th>\n",
              "      <th>Tumor_purity</th>\n",
              "      <th>histological_type</th>\n",
              "      <th>gender</th>\n",
              "      <th>radiation_therapy</th>\n",
              "      <th>race</th>\n",
              "      <th>ethnicity</th>\n",
              "      <th>overall_survival</th>\n",
              "      <th>status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TCGA.02.0001</td>\n",
              "      <td>44</td>\n",
              "      <td>0.7876</td>\n",
              "      <td>untreatedprimary(denovo)gbm</td>\n",
              "      <td>female</td>\n",
              "      <td>yes</td>\n",
              "      <td>white</td>\n",
              "      <td>nothispanicorlatino</td>\n",
              "      <td>358.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TCGA.02.0003</td>\n",
              "      <td>50</td>\n",
              "      <td>0.9850</td>\n",
              "      <td>untreatedprimary(denovo)gbm</td>\n",
              "      <td>male</td>\n",
              "      <td>yes</td>\n",
              "      <td>white</td>\n",
              "      <td>nothispanicorlatino</td>\n",
              "      <td>144.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TCGA.02.0004</td>\n",
              "      <td>59</td>\n",
              "      <td>0.7937</td>\n",
              "      <td>untreatedprimary(denovo)gbm</td>\n",
              "      <td>male</td>\n",
              "      <td>yes</td>\n",
              "      <td>white</td>\n",
              "      <td>nothispanicorlatino</td>\n",
              "      <td>345.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TCGA.02.0007</td>\n",
              "      <td>40</td>\n",
              "      <td>0.9850</td>\n",
              "      <td>treatedprimarygbm</td>\n",
              "      <td>female</td>\n",
              "      <td>yes</td>\n",
              "      <td>white</td>\n",
              "      <td>nothispanicorlatino</td>\n",
              "      <td>705.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TCGA.02.0009</td>\n",
              "      <td>61</td>\n",
              "      <td>0.9850</td>\n",
              "      <td>untreatedprimary(denovo)gbm</td>\n",
              "      <td>female</td>\n",
              "      <td>yes</td>\n",
              "      <td>white</td>\n",
              "      <td>nothispanicorlatino</td>\n",
              "      <td>322.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    attrib_name  years_to_birth  ...  overall_survival status\n",
              "0  TCGA.02.0001              44  ...             358.0    1.0\n",
              "1  TCGA.02.0003              50  ...             144.0    1.0\n",
              "2  TCGA.02.0004              59  ...             345.0    1.0\n",
              "3  TCGA.02.0007              40  ...             705.0    1.0\n",
              "4  TCGA.02.0009              61  ...             322.0    1.0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alo5Ns7sU8E3"
      },
      "source": [
        "tfd = tfp.distributions\n",
        "tfpl = tfp.layers\n",
        "tfb = tfp.bijectors\n",
        "\n",
        "data=pd.read_excel('RNA_seq_1.xlsx')\n",
        "#data2=pd.read_excel('C://Personal//Unf Course Folder//Spring 2021//Applied Predictive Modelling//RNA_seq_2.xlsx')\n",
        "data=data.T\n",
        "sample_names=list(data.index)\n",
        "sample_names=sample_names[1:]\n",
        "feature=data.iloc[0,:]\n",
        "data=data.drop(index='attrib_name')\n",
        "data.columns=feature\n",
        "#check if we have null values\n",
        "isnull=pd.isnull(data)\n",
        "countmissing=isnull.sum(axis=0)\n",
        "total_missing=countmissing.sum()\n",
        "#There are 191 missing values from [\"RAC1\"] gene. I will drop this column\n",
        "data=data.drop(['RAC1'],axis=1)\n",
        "\n",
        "#convert dataframe to numpy array\n",
        "X=np.asarray(data).astype(np.float32)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H34Hq8SJ9gb"
      },
      "source": [
        "X=np.delete(X,[372,458,462],axis=0)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDqq-PogQtjv",
        "outputId": "2297e366-579f-40e7-ec27-3e8d20750a34"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(525, 4570)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDc6kVYDJ8ST"
      },
      "source": [
        "X_temp, X_test, y_temp, y_test = train_test_split(X, X, test_size=0.20, random_state=42)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMs9pCdjleGp"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.10, random_state=42)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MyE94HtNWy5",
        "outputId": "761acc1e-2861-4d9e-9711-4a4218595c17"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105, 4570)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNkgmUbYN58j"
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices(X_train)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices(X_test)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices(X_val)\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOV_59KTOQkT",
        "outputId": "8c32fde6-a078-41e2-be22-4e5c43c18b53"
      },
      "source": [
        "batch_size = 32\n",
        "train_ds = train_ds.batch(batch_size)\n",
        "val_ds = val_ds.batch(batch_size)\n",
        "test_ds = test_ds.batch(batch_size)\n",
        "train_ds"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: (None, 4570), types: tf.float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE-dMKi2b3bg"
      },
      "source": [
        "def get_prior(num_modes, latent_dim):\n",
        "    \"\"\"\n",
        "    This function should create an instance of a MixtureSameFamily distribution \n",
        "    according to the above specification. \n",
        "    The function takes the num_modes and latent_dim as arguments, which should \n",
        "    be used to define the distribution.\n",
        "    Your function should then return the distribution instance.\n",
        "    \"\"\"\n",
        "    prior = tfd.MixtureSameFamily(\n",
        "        mixture_distribution=tfd.Categorical(probs=tf.ones(num_modes)/num_modes),\n",
        "        components_distribution=tfd.MultivariateNormalDiag(\n",
        "                                    loc=tf.Variable(tf.random.normal([num_modes, latent_dim])),\n",
        "                                    scale_diag=tfp.util.TransformedVariable(tf.ones((num_modes,latent_dim), dtype='float32'), bijector=tfb.Softplus(), dtype='float32')))\n",
        "    return prior"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUxWCoyLdHvd",
        "outputId": "e4cfeb70-6785-4df6-c487-84bf27ec610f"
      },
      "source": [
        "prior = get_prior(num_modes=2, latent_dim=10)\n",
        "prior\n",
        "#prior=tf.random.normal([2,50])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tfp.distributions.MixtureSameFamily 'MixtureSameFamily' batch_shape=[] event_shape=[10] dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5numamJXcZ8K"
      },
      "source": [
        "\n",
        "def get_kl_regularizer(prior_distribution):\n",
        "    \"\"\"\n",
        "    This function should create an instance of the KLDivergenceRegularizer \n",
        "    according to the above specification. \n",
        "    The function takes the prior_distribution, which should be used to define \n",
        "    the distribution.\n",
        "    Your function should then return the KLDivergenceRegularizer instance.\n",
        "    \"\"\"\n",
        "    regularizer=tfpl.KLDivergenceRegularizer(prior_distribution,use_exact_kl=False,weight=1.0,test_points_fn=lambda q:q.sample(3),test_points_reduce_axis=(0,1))\n",
        "    return regularizer"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gDiTbMyhNFy"
      },
      "source": [
        "kl_regularizer = get_kl_regularizer(prior)  "
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwTAcq0UcroH"
      },
      "source": [
        "def get_encoder(latent_dim, kl_regularizer):\n",
        "    \"\"\"\n",
        "    This function should build an encoder model according to the above specification. \n",
        "    The function takes latent_dim and kl_regularizer as arguments, which should be\n",
        "    used to define the model.\n",
        "    Your function should return the encoder model.\n",
        "    \"\"\"\n",
        "    model=Sequential([Dense(units=100,activation='relu',input_shape=(4570,)),\n",
        "                      Dense(tfpl.MultivariateNormalTriL.params_size(latent_dim)),\n",
        "                      tfpl.MultivariateNormalTriL(latent_dim,activity_regularizer=kl_regularizer)\n",
        "                     ])\n",
        "    return model"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yo9M2bYBhRUJ",
        "outputId": "476f22d7-3d1d-46d1-bf91-7073b7c60a82"
      },
      "source": [
        "encoder = get_encoder(latent_dim=10, kl_regularizer=kl_regularizer)\n",
        "encoder"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f3d1ef25b10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiK9MXE4n_gn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e547eb64-9c3b-4105-88b7-fca4b53d2ed8"
      },
      "source": [
        "encoder.summary()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 100)               457100    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 65)                6565      \n",
            "_________________________________________________________________\n",
            "multivariate_normal_tri_l_1  multiple                  40        \n",
            "=================================================================\n",
            "Total params: 463,705\n",
            "Trainable params: 463,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zVNoIoSWKTs"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ-H6m9ORbbw"
      },
      "source": [
        "def get_decoder(latent_dim):\n",
        "    \"\"\"\n",
        "    This function should build a CNN decoder model according to the above specification. \n",
        "    The function takes latent_dim as an argument, which should be used to define the model.\n",
        "    Your function should return the decoder model.\n",
        "    \"\"\"\n",
        "    decoder=Sequential([Dense(100,activation='relu',input_shape=(latent_dim,)),\n",
        "                        tfpl.IndependentBernoulli((4570,))\n",
        "                       ])\n",
        "    return decoder"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZfCPceCsQXN"
      },
      "source": [
        "decoder = get_decoder(latent_dim=10)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHbgffEWjX7I",
        "outputId": "d4d59052-a95c-410f-c15d-4c3a16a1f998"
      },
      "source": [
        "encoder.summary()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 100)               457100    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 65)                6565      \n",
            "_________________________________________________________________\n",
            "multivariate_normal_tri_l_1  multiple                  40        \n",
            "=================================================================\n",
            "Total params: 463,705\n",
            "Trainable params: 463,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDiDsiqIjpox"
      },
      "source": [
        "def reconstruction_loss(batch_of_data, decoding_dist):\n",
        "    \"\"\"\n",
        "    This function should compute and return the average expected reconstruction loss,\n",
        "    as defined above.\n",
        "    The function takes batch_of_data (Tensor containing a batch of input data to\n",
        "    the encoder) and decoding_dist (output distribution of decoder after passing the \n",
        "    image batch through the encoder and decoder) as arguments.\n",
        "    The function should return the scalar average expected reconstruction loss.\n",
        "    \"\"\"\n",
        "    return -tf.reduce_mean(decoding_dist.log_prob(batch_of_images))\n",
        "    "
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn4NwKbzj6Hu",
        "outputId": "0632d4bf-e0f6-4359-d779-b1c79ceed70c"
      },
      "source": [
        "\n",
        "vae = Model(inputs=encoder.inputs, outputs=decoder(encoder.outputs))\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
        "vae.compile(optimizer=optimizer, loss=reconstruction_loss, metrics=[\"Accuracy\"])\n",
        "vae"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.functional.Functional at 0x7f3d1cd90f10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWchahh2kAuP",
        "outputId": "4feb50f9-014c-4c98-b675-2aa64eaec3d1"
      },
      "source": [
        "  history=vae.fit(train_ds, validation_data=val_ds, epochs=100)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_5/kernel:0', 'dense_5/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_5/kernel:0', 'dense_5/bias:0'] when minimizing the loss.\n",
            "12/12 [==============================] - 5s 101ms/step - loss: 21.0050 - accuracy: 0.0000e+00 - val_loss: 0.8480 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3914 - accuracy: 0.0000e+00 - val_loss: 0.7777 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3885 - accuracy: 0.0000e+00 - val_loss: 0.8505 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3874 - accuracy: 0.0000e+00 - val_loss: 0.7565 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3830 - accuracy: 0.0000e+00 - val_loss: 0.7391 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3686 - accuracy: 0.0000e+00 - val_loss: 0.7765 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3673 - accuracy: 0.0000e+00 - val_loss: 0.7551 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3660 - accuracy: 0.0000e+00 - val_loss: 0.7833 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3583 - accuracy: 0.0000e+00 - val_loss: 0.7408 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3573 - accuracy: 0.0000e+00 - val_loss: 0.7356 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3510 - accuracy: 0.0000e+00 - val_loss: 0.6592 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3428 - accuracy: 0.0000e+00 - val_loss: 0.6832 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3395 - accuracy: 0.0000e+00 - val_loss: 0.7445 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3346 - accuracy: 0.0000e+00 - val_loss: 0.7282 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3324 - accuracy: 0.0000e+00 - val_loss: 0.6536 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3259 - accuracy: 0.0000e+00 - val_loss: 0.6677 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3180 - accuracy: 0.0000e+00 - val_loss: 0.6203 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3203 - accuracy: 0.0000e+00 - val_loss: 0.6839 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3097 - accuracy: 0.0000e+00 - val_loss: 0.6314 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3068 - accuracy: 0.0000e+00 - val_loss: 0.6338 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3025 - accuracy: 0.0000e+00 - val_loss: 0.6532 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2960 - accuracy: 0.0000e+00 - val_loss: 0.6576 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2893 - accuracy: 0.0000e+00 - val_loss: 0.5953 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2872 - accuracy: 0.0000e+00 - val_loss: 0.5424 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2839 - accuracy: 0.0000e+00 - val_loss: 0.6145 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2823 - accuracy: 0.0000e+00 - val_loss: 0.5817 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2727 - accuracy: 0.0000e+00 - val_loss: 0.5369 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2708 - accuracy: 0.0000e+00 - val_loss: 0.5193 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2665 - accuracy: 0.0000e+00 - val_loss: 0.5973 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2615 - accuracy: 0.0000e+00 - val_loss: 0.5834 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2581 - accuracy: 0.0000e+00 - val_loss: 0.5941 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2484 - accuracy: 0.0000e+00 - val_loss: 0.4515 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2477 - accuracy: 0.0000e+00 - val_loss: 0.4960 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2432 - accuracy: 0.0000e+00 - val_loss: 0.5221 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.2454 - accuracy: 0.0000e+00 - val_loss: 0.4924 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.2340 - accuracy: 0.0000e+00 - val_loss: 0.4701 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.2334 - accuracy: 0.0000e+00 - val_loss: 0.5051 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.2358 - accuracy: 0.0000e+00 - val_loss: 0.4981 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.2211 - accuracy: 0.0000e+00 - val_loss: 0.4816 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.2172 - accuracy: 0.0000e+00 - val_loss: 0.4530 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.2181 - accuracy: 0.0000e+00 - val_loss: 0.4353 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2107 - accuracy: 0.0000e+00 - val_loss: 0.4570 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2100 - accuracy: 0.0000e+00 - val_loss: 0.4503 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2049 - accuracy: 0.0000e+00 - val_loss: 0.4195 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2035 - accuracy: 0.0000e+00 - val_loss: 0.3714 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1971 - accuracy: 0.0000e+00 - val_loss: 0.3964 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1955 - accuracy: 0.0000e+00 - val_loss: 0.4014 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1923 - accuracy: 0.0000e+00 - val_loss: 0.3536 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1886 - accuracy: 0.0000e+00 - val_loss: 0.3712 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1885 - accuracy: 0.0000e+00 - val_loss: 0.4206 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1794 - accuracy: 0.0000e+00 - val_loss: 0.3681 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1740 - accuracy: 0.0000e+00 - val_loss: 0.3570 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1727 - accuracy: 0.0000e+00 - val_loss: 0.3618 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1767 - accuracy: 0.0000e+00 - val_loss: 0.3627 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1667 - accuracy: 0.0000e+00 - val_loss: 0.3230 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1601 - accuracy: 0.0000e+00 - val_loss: 0.3705 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1666 - accuracy: 0.0000e+00 - val_loss: 0.3691 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1598 - accuracy: 0.0000e+00 - val_loss: 0.3374 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1532 - accuracy: 0.0000e+00 - val_loss: 0.3088 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1525 - accuracy: 0.0000e+00 - val_loss: 0.2660 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1515 - accuracy: 0.0000e+00 - val_loss: 0.3221 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1516 - accuracy: 0.0000e+00 - val_loss: 0.2806 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1471 - accuracy: 0.0000e+00 - val_loss: 0.2676 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1397 - accuracy: 0.0000e+00 - val_loss: 0.2974 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1406 - accuracy: 0.0000e+00 - val_loss: 0.3116 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1395 - accuracy: 0.0000e+00 - val_loss: 0.2773 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1373 - accuracy: 0.0000e+00 - val_loss: 0.3087 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1346 - accuracy: 0.0000e+00 - val_loss: 0.2625 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1290 - accuracy: 0.0000e+00 - val_loss: 0.2404 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1252 - accuracy: 0.0000e+00 - val_loss: 0.2376 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1285 - accuracy: 0.0000e+00 - val_loss: 0.2559 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1202 - accuracy: 0.0000e+00 - val_loss: 0.2808 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1170 - accuracy: 0.0000e+00 - val_loss: 0.2493 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1175 - accuracy: 0.0000e+00 - val_loss: 0.2385 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1154 - accuracy: 0.0000e+00 - val_loss: 0.2591 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1138 - accuracy: 0.0000e+00 - val_loss: 0.2089 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1095 - accuracy: 0.0000e+00 - val_loss: 0.1870 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1112 - accuracy: 0.0000e+00 - val_loss: 0.2182 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1057 - accuracy: 0.0000e+00 - val_loss: 0.2303 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1025 - accuracy: 0.0000e+00 - val_loss: 0.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1040 - accuracy: 0.0000e+00 - val_loss: 0.2019 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0989 - accuracy: 0.0000e+00 - val_loss: 0.2221 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0988 - accuracy: 0.0000e+00 - val_loss: 0.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0955 - accuracy: 0.0000e+00 - val_loss: 0.2198 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0909 - accuracy: 0.0000e+00 - val_loss: 0.1776 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0900 - accuracy: 0.0000e+00 - val_loss: 0.1550 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0877 - accuracy: 0.0000e+00 - val_loss: 0.1950 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0889 - accuracy: 0.0000e+00 - val_loss: 0.1614 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0880 - accuracy: 0.0000e+00 - val_loss: 0.1923 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0859 - accuracy: 0.0000e+00 - val_loss: 0.1362 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0826 - accuracy: 0.0000e+00 - val_loss: 0.1666 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0812 - accuracy: 0.0000e+00 - val_loss: 0.1536 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0804 - accuracy: 0.0000e+00 - val_loss: 0.1615 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0820 - accuracy: 0.0000e+00 - val_loss: 0.1514 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0762 - accuracy: 0.0000e+00 - val_loss: 0.1842 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0729 - accuracy: 0.0000e+00 - val_loss: 0.1570 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0741 - accuracy: 0.0000e+00 - val_loss: 0.1274 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0725 - accuracy: 0.0000e+00 - val_loss: 0.1420 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0667 - accuracy: 0.0000e+00 - val_loss: 0.1479 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0684 - accuracy: 0.0000e+00 - val_loss: 0.1606 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "mpxa5bZzlzTE",
        "outputId": "dfe8173a-a74d-4d2e-b5a8-e52c67b5c990"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['Training_loss','Val_loss'])\n",
        "plt.title('Loss vs Epoch')\n",
        "plt.savefig('Loss_var')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsfwiW_ym4JG"
      },
      "source": [
        "def reconstruct(encoder, decoder, batch_of_genes):\n",
        "    \"\"\"\n",
        "    This function should compute reconstructions of the batch_of_genes according\n",
        "    to the above instructions.\n",
        "    The function takes the encoder, decoder and batch_of_genes as inputs, which\n",
        "    should be used to compute the reconstructions.\n",
        "    The function should then return the reconstructions Tensor.\n",
        "    \"\"\"\n",
        "    encodings = encoder(batch_of_genes)\n",
        "    decodings=decoder(encodings.mean()).mean()\n",
        "    \n",
        "    return decodings\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrfZcFxgr-Su"
      },
      "source": [
        "b=X_test[0:2,:]\n",
        "b.shape\n",
        "encodings=encoder(X)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRqLhVVpAmKi",
        "outputId": "5de1f9c3-9155-4e2f-d4f9-06b2ea55992a"
      },
      "source": [
        "encodings"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tfp.distributions.MultivariateNormalTriL 'sequential_2_multivariate_normal_tri_l_1_MultivariateNormalTriL_MultivariateNormalTriL' batch_shape=[525] event_shape=[10] dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qynJXTwVbNAi"
      },
      "source": [
        "features=encodings.sample().numpy()"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Dqzbhw9OEpdi",
        "outputId": "37d8adc3-a0b4-4e47-c4bf-cb4f67c994c8"
      },
      "source": [
        "features=pd.DataFrame(features)\n",
        "features"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.750713</td>\n",
              "      <td>-0.264170</td>\n",
              "      <td>-1.732696</td>\n",
              "      <td>-0.382637</td>\n",
              "      <td>0.130948</td>\n",
              "      <td>-0.286804</td>\n",
              "      <td>-0.537604</td>\n",
              "      <td>-0.520043</td>\n",
              "      <td>1.359504</td>\n",
              "      <td>-0.260532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.126037</td>\n",
              "      <td>0.113939</td>\n",
              "      <td>-1.228748</td>\n",
              "      <td>-0.805015</td>\n",
              "      <td>-0.318522</td>\n",
              "      <td>1.375131</td>\n",
              "      <td>0.330537</td>\n",
              "      <td>-0.522685</td>\n",
              "      <td>0.670305</td>\n",
              "      <td>-0.450734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.189679</td>\n",
              "      <td>0.196028</td>\n",
              "      <td>0.622810</td>\n",
              "      <td>-0.449176</td>\n",
              "      <td>0.555818</td>\n",
              "      <td>0.241020</td>\n",
              "      <td>1.850960</td>\n",
              "      <td>0.942064</td>\n",
              "      <td>1.134398</td>\n",
              "      <td>-0.056417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.383453</td>\n",
              "      <td>-0.758757</td>\n",
              "      <td>0.542443</td>\n",
              "      <td>-2.132998</td>\n",
              "      <td>-0.100129</td>\n",
              "      <td>1.458055</td>\n",
              "      <td>-1.602010</td>\n",
              "      <td>-0.695038</td>\n",
              "      <td>0.506275</td>\n",
              "      <td>-2.021970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.858441</td>\n",
              "      <td>0.263830</td>\n",
              "      <td>0.561312</td>\n",
              "      <td>1.158930</td>\n",
              "      <td>-0.390611</td>\n",
              "      <td>-0.760670</td>\n",
              "      <td>-0.401866</td>\n",
              "      <td>-1.306166</td>\n",
              "      <td>1.870169</td>\n",
              "      <td>1.235928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520</th>\n",
              "      <td>1.207107</td>\n",
              "      <td>0.306343</td>\n",
              "      <td>-0.184196</td>\n",
              "      <td>-0.256031</td>\n",
              "      <td>0.270494</td>\n",
              "      <td>0.280542</td>\n",
              "      <td>-1.256153</td>\n",
              "      <td>0.236448</td>\n",
              "      <td>1.177843</td>\n",
              "      <td>0.056330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>521</th>\n",
              "      <td>-0.650870</td>\n",
              "      <td>0.595766</td>\n",
              "      <td>-0.045400</td>\n",
              "      <td>0.053234</td>\n",
              "      <td>-0.305393</td>\n",
              "      <td>0.438365</td>\n",
              "      <td>-1.324404</td>\n",
              "      <td>-0.299118</td>\n",
              "      <td>1.287890</td>\n",
              "      <td>1.326913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>522</th>\n",
              "      <td>-0.101025</td>\n",
              "      <td>-0.214929</td>\n",
              "      <td>-1.358341</td>\n",
              "      <td>0.904105</td>\n",
              "      <td>-1.298545</td>\n",
              "      <td>0.933941</td>\n",
              "      <td>-2.077636</td>\n",
              "      <td>0.339750</td>\n",
              "      <td>-0.066728</td>\n",
              "      <td>0.556046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>0.106782</td>\n",
              "      <td>-0.657348</td>\n",
              "      <td>-0.895035</td>\n",
              "      <td>0.426090</td>\n",
              "      <td>-0.496813</td>\n",
              "      <td>-0.639957</td>\n",
              "      <td>0.126763</td>\n",
              "      <td>-0.857128</td>\n",
              "      <td>0.137586</td>\n",
              "      <td>1.195022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>0.901587</td>\n",
              "      <td>-0.975403</td>\n",
              "      <td>-1.146194</td>\n",
              "      <td>-0.679417</td>\n",
              "      <td>-1.593491</td>\n",
              "      <td>0.726671</td>\n",
              "      <td>-1.045336</td>\n",
              "      <td>-0.676044</td>\n",
              "      <td>0.582051</td>\n",
              "      <td>-0.933608</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>525 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2  ...         7         8         9\n",
              "0   -0.750713 -0.264170 -1.732696  ... -0.520043  1.359504 -0.260532\n",
              "1   -0.126037  0.113939 -1.228748  ... -0.522685  0.670305 -0.450734\n",
              "2   -1.189679  0.196028  0.622810  ...  0.942064  1.134398 -0.056417\n",
              "3   -0.383453 -0.758757  0.542443  ... -0.695038  0.506275 -2.021970\n",
              "4   -0.858441  0.263830  0.561312  ... -1.306166  1.870169  1.235928\n",
              "..        ...       ...       ...  ...       ...       ...       ...\n",
              "520  1.207107  0.306343 -0.184196  ...  0.236448  1.177843  0.056330\n",
              "521 -0.650870  0.595766 -0.045400  ... -0.299118  1.287890  1.326913\n",
              "522 -0.101025 -0.214929 -1.358341  ...  0.339750 -0.066728  0.556046\n",
              "523  0.106782 -0.657348 -0.895035  ... -0.857128  0.137586  1.195022\n",
              "524  0.901587 -0.975403 -1.146194  ... -0.676044  0.582051 -0.933608\n",
              "\n",
              "[525 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkxVATOjFgz8"
      },
      "source": [
        "features.columns=[\"feature1\",\"feature2\",\"feature3\",\"feature4\",\"feature5\",\"feature6\",\"feature7\",\"feature8\",\"feature9\",\"feature10\"]"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CELMUP-IEoTA"
      },
      "source": [
        "scalar=StandardScaler().fit(features)\n",
        "scaled=pd.DataFrame((scalar.fit_transform(features)))\n",
        "\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM6hKGQQWXDK"
      },
      "source": [
        "scaled.columns=features.columns"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIWvbHzpI42g"
      },
      "source": [
        "finaldata=pd.concat([clinical_data,scaled],axis=1)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqspFZ_oYPtK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "2540d0da-4ac8-4d72-9a31-cb570327065b"
      },
      "source": [
        "finaldata"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attrib_name</th>\n",
              "      <th>years_to_birth</th>\n",
              "      <th>Tumor_purity</th>\n",
              "      <th>histological_type</th>\n",
              "      <th>gender</th>\n",
              "      <th>radiation_therapy</th>\n",
              "      <th>race</th>\n",
              "      <th>ethnicity</th>\n",
              "      <th>overall_survival</th>\n",
              "      <th>status</th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TCGA.02.0001</td>\n",
              "      <td>44</td>\n",
              "      <td>0.7876</td>\n",
              "      <td>untreatedprimary(denovo)gbm</td>\n",
              "      <td>female</td>\n",
              "      <td>yes</td>\n",
              "      <td>white</td>\n",
              "      <td>nothispanicorlatino</td>\n",
              "      <td>358.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.912300</td>\n",
              "      <td>0.021216</td>\n",
              "      <td>-1.580327</td>\n",
              "      <td>-0.141815</td>\n",
              "      <td>0.536153</td>\n",
              "      <td>-0.079910</td>\n",
              "      <td>-0.280532</td>\n",
              "      <td>-0.560789</td>\n",
              "      <td>1.058499</td>\n",
              "      <td>-0.334538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TCGA.02.0003</td>\n",
              "      <td>50</td>\n",
              "      <td>0.9850</td>\n",
              "      <td>untreatedprimary(denovo)gbm</td>\n",
              "      <td>male</td>\n",
              "      <td>yes</td>\n",
              "      <td>white</td>\n",
              "      <td>nothispanicorlatino</td>\n",
              "      <td>144.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.244209</td>\n",
              "      <td>0.476432</td>\n",
              "      <td>-1.036794</td>\n",
              "      <td>-0.588086</td>\n",
              "      <td>0.037263</td>\n",
              "      <td>1.879867</td>\n",
              "      <td>0.700296</td>\n",
              "      <td>-0.563669</td>\n",
              "      <td>0.241410</td>\n",
              "      <td>-0.530486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TCGA.02.0004</td>\n",
              "      <td>59</td>\n",
              "      <td>0.7937</td>\n",
              "      <td>untreatedprimary(denovo)gbm</td>\n",
              "      <td>male</td>\n",
              "      <td>yes</td>\n",
              "      <td>white</td>\n",
              "      <td>nothispanicorlatino</td>\n",
              "      <td>345.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.381774</td>\n",
              "      <td>0.575262</td>\n",
              "      <td>0.960204</td>\n",
              "      <td>-0.212119</td>\n",
              "      <td>1.007737</td>\n",
              "      <td>0.542507</td>\n",
              "      <td>2.418075</td>\n",
              "      <td>1.033209</td>\n",
              "      <td>0.791622</td>\n",
              "      <td>-0.124257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TCGA.02.0007</td>\n",
              "      <td>40</td>\n",
              "      <td>0.9850</td>\n",
              "      <td>treatedprimarygbm</td>\n",
              "      <td>female</td>\n",
              "      <td>yes</td>\n",
              "      <td>white</td>\n",
              "      <td>nothispanicorlatino</td>\n",
              "      <td>705.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.519516</td>\n",
              "      <td>-0.574232</td>\n",
              "      <td>0.873524</td>\n",
              "      <td>-1.991187</td>\n",
              "      <td>0.279669</td>\n",
              "      <td>1.977652</td>\n",
              "      <td>-1.483102</td>\n",
              "      <td>-0.751569</td>\n",
              "      <td>0.046941</td>\n",
              "      <td>-2.149184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TCGA.02.0009</td>\n",
              "      <td>61</td>\n",
              "      <td>0.9850</td>\n",
              "      <td>untreatedprimary(denovo)gbm</td>\n",
              "      <td>female</td>\n",
              "      <td>yes</td>\n",
              "      <td>white</td>\n",
              "      <td>nothispanicorlatino</td>\n",
              "      <td>322.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.027515</td>\n",
              "      <td>0.656891</td>\n",
              "      <td>0.893875</td>\n",
              "      <td>1.486950</td>\n",
              "      <td>-0.042752</td>\n",
              "      <td>-0.638698</td>\n",
              "      <td>-0.127175</td>\n",
              "      <td>-1.417825</td>\n",
              "      <td>1.663926</td>\n",
              "      <td>1.207126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520</th>\n",
              "      <td>TCGA.76.6193</td>\n",
              "      <td>78</td>\n",
              "      <td>0.6246</td>\n",
              "      <td>untreatedprimary(denovo)gbm</td>\n",
              "      <td>male</td>\n",
              "      <td>yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>82.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.181589</td>\n",
              "      <td>0.708074</td>\n",
              "      <td>0.089808</td>\n",
              "      <td>-0.008048</td>\n",
              "      <td>0.691041</td>\n",
              "      <td>0.589113</td>\n",
              "      <td>-1.092351</td>\n",
              "      <td>0.263943</td>\n",
              "      <td>0.843129</td>\n",
              "      <td>-0.008105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>521</th>\n",
              "      <td>TCGA.76.6282</td>\n",
              "      <td>63</td>\n",
              "      <td>0.7034</td>\n",
              "      <td>untreatedprimary(denovo)gbm</td>\n",
              "      <td>male</td>\n",
              "      <td>yes</td>\n",
              "      <td>white</td>\n",
              "      <td>nothispanicorlatino</td>\n",
              "      <td>519.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.805518</td>\n",
              "      <td>1.056518</td>\n",
              "      <td>0.239507</td>\n",
              "      <td>0.318711</td>\n",
              "      <td>0.051836</td>\n",
              "      <td>0.775219</td>\n",
              "      <td>-1.169461</td>\n",
              "      <td>-0.319936</td>\n",
              "      <td>0.973596</td>\n",
              "      <td>1.300858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>522</th>\n",
              "      <td>TCGA.76.6285</td>\n",
              "      <td>64</td>\n",
              "      <td>0.7913</td>\n",
              "      <td>untreatedprimary(denovo)gbm</td>\n",
              "      <td>female</td>\n",
              "      <td>no</td>\n",
              "      <td>white</td>\n",
              "      <td>NaN</td>\n",
              "      <td>254.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.217459</td>\n",
              "      <td>0.080498</td>\n",
              "      <td>-1.176566</td>\n",
              "      <td>1.217711</td>\n",
              "      <td>-1.050512</td>\n",
              "      <td>1.359610</td>\n",
              "      <td>-2.020466</td>\n",
              "      <td>0.376563</td>\n",
              "      <td>-0.632390</td>\n",
              "      <td>0.506706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>TCGA.81.5910</td>\n",
              "      <td>64</td>\n",
              "      <td>0.7913</td>\n",
              "      <td>untreatedprimary(denovo)gbm</td>\n",
              "      <td>male</td>\n",
              "      <td>no</td>\n",
              "      <td>white</td>\n",
              "      <td>NaN</td>\n",
              "      <td>49.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.004791</td>\n",
              "      <td>-0.452144</td>\n",
              "      <td>-0.676868</td>\n",
              "      <td>0.712657</td>\n",
              "      <td>-0.160630</td>\n",
              "      <td>-0.496352</td>\n",
              "      <td>0.470072</td>\n",
              "      <td>-0.928281</td>\n",
              "      <td>-0.390164</td>\n",
              "      <td>1.164984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>TCGA.87.5896</td>\n",
              "      <td>50</td>\n",
              "      <td>0.8880</td>\n",
              "      <td>untreatedprimary(denovo)gbm</td>\n",
              "      <td>female</td>\n",
              "      <td>yes</td>\n",
              "      <td>white</td>\n",
              "      <td>nothispanicorlatino</td>\n",
              "      <td>800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.854834</td>\n",
              "      <td>-0.835060</td>\n",
              "      <td>-0.947755</td>\n",
              "      <td>-0.455384</td>\n",
              "      <td>-1.377887</td>\n",
              "      <td>1.115194</td>\n",
              "      <td>-0.854169</td>\n",
              "      <td>-0.730861</td>\n",
              "      <td>0.136779</td>\n",
              "      <td>-1.027946</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>525 rows × 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      attrib_name  years_to_birth  Tumor_purity  ...  feature8  feature9 feature10\n",
              "0    TCGA.02.0001              44        0.7876  ... -0.560789  1.058499 -0.334538\n",
              "1    TCGA.02.0003              50        0.9850  ... -0.563669  0.241410 -0.530486\n",
              "2    TCGA.02.0004              59        0.7937  ...  1.033209  0.791622 -0.124257\n",
              "3    TCGA.02.0007              40        0.9850  ... -0.751569  0.046941 -2.149184\n",
              "4    TCGA.02.0009              61        0.9850  ... -1.417825  1.663926  1.207126\n",
              "..            ...             ...           ...  ...       ...       ...       ...\n",
              "520  TCGA.76.6193              78        0.6246  ...  0.263943  0.843129 -0.008105\n",
              "521  TCGA.76.6282              63        0.7034  ... -0.319936  0.973596  1.300858\n",
              "522  TCGA.76.6285              64        0.7913  ...  0.376563 -0.632390  0.506706\n",
              "523  TCGA.81.5910              64        0.7913  ... -0.928281 -0.390164  1.164984\n",
              "524  TCGA.87.5896              50        0.8880  ... -0.730861  0.136779 -1.027946\n",
              "\n",
              "[525 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKbMwNBo0FEw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veFuVGp8YwQC"
      },
      "source": [
        "final_samples=finaldata[\"attrib_name\"]\n",
        "finaldata.drop(columns=[\"attrib_name\",\"histological_type\",\"radiation_therapy\",\"race\",\"ethnicity\",],inplace=True)\n",
        "#finaldata.columns=['years_to_birth','Tumor_purity','gender','overall_survival','status','feature1','feature2','feature3','feature4','feature5']\n",
        "finaldata[\"years_to_birth\"]=finaldata[\"years_to_birth\"].astype(int)\n",
        "finaldata[\"Tumor_purity\"]=finaldata[\"Tumor_purity\"].astype(float)\n",
        "finaldata.drop(finaldata[finaldata['status'].isna()].index, inplace = True)\n",
        "finaldata[\"status\"]=finaldata[\"status\"].astype(int)\n",
        "lc=LabelEncoder()\n",
        "finaldata[\"gender\"]=lc.fit_transform(finaldata.gender)\n",
        "    #Replace Nan Tumor purity mean values\n",
        "    \n",
        "finaldata.replace(to_replace = np.nan, value =0,inplace=True)\n",
        "finaldata['Tumor_purity'].replace(to_replace = np.nan, value =0.8456692607003896,inplace=True)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "v4Rxm3refbIc",
        "outputId": "9060c688-8904-4ff8-a1ef-49eb677cf786"
      },
      "source": [
        "finaldata"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>years_to_birth</th>\n",
              "      <th>Tumor_purity</th>\n",
              "      <th>gender</th>\n",
              "      <th>overall_survival</th>\n",
              "      <th>status</th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>44</td>\n",
              "      <td>0.7876</td>\n",
              "      <td>0</td>\n",
              "      <td>358.0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.912300</td>\n",
              "      <td>0.021216</td>\n",
              "      <td>-1.580327</td>\n",
              "      <td>-0.141815</td>\n",
              "      <td>0.536153</td>\n",
              "      <td>-0.079910</td>\n",
              "      <td>-0.280532</td>\n",
              "      <td>-0.560789</td>\n",
              "      <td>1.058499</td>\n",
              "      <td>-0.334538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>0.9850</td>\n",
              "      <td>1</td>\n",
              "      <td>144.0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.244209</td>\n",
              "      <td>0.476432</td>\n",
              "      <td>-1.036794</td>\n",
              "      <td>-0.588086</td>\n",
              "      <td>0.037263</td>\n",
              "      <td>1.879867</td>\n",
              "      <td>0.700296</td>\n",
              "      <td>-0.563669</td>\n",
              "      <td>0.241410</td>\n",
              "      <td>-0.530486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>59</td>\n",
              "      <td>0.7937</td>\n",
              "      <td>1</td>\n",
              "      <td>345.0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.381774</td>\n",
              "      <td>0.575262</td>\n",
              "      <td>0.960204</td>\n",
              "      <td>-0.212119</td>\n",
              "      <td>1.007737</td>\n",
              "      <td>0.542507</td>\n",
              "      <td>2.418075</td>\n",
              "      <td>1.033209</td>\n",
              "      <td>0.791622</td>\n",
              "      <td>-0.124257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40</td>\n",
              "      <td>0.9850</td>\n",
              "      <td>0</td>\n",
              "      <td>705.0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.519516</td>\n",
              "      <td>-0.574232</td>\n",
              "      <td>0.873524</td>\n",
              "      <td>-1.991187</td>\n",
              "      <td>0.279669</td>\n",
              "      <td>1.977652</td>\n",
              "      <td>-1.483102</td>\n",
              "      <td>-0.751569</td>\n",
              "      <td>0.046941</td>\n",
              "      <td>-2.149184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>61</td>\n",
              "      <td>0.9850</td>\n",
              "      <td>0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.027515</td>\n",
              "      <td>0.656891</td>\n",
              "      <td>0.893875</td>\n",
              "      <td>1.486950</td>\n",
              "      <td>-0.042752</td>\n",
              "      <td>-0.638698</td>\n",
              "      <td>-0.127175</td>\n",
              "      <td>-1.417825</td>\n",
              "      <td>1.663926</td>\n",
              "      <td>1.207126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520</th>\n",
              "      <td>78</td>\n",
              "      <td>0.6246</td>\n",
              "      <td>1</td>\n",
              "      <td>82.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.181589</td>\n",
              "      <td>0.708074</td>\n",
              "      <td>0.089808</td>\n",
              "      <td>-0.008048</td>\n",
              "      <td>0.691041</td>\n",
              "      <td>0.589113</td>\n",
              "      <td>-1.092351</td>\n",
              "      <td>0.263943</td>\n",
              "      <td>0.843129</td>\n",
              "      <td>-0.008105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>521</th>\n",
              "      <td>63</td>\n",
              "      <td>0.7034</td>\n",
              "      <td>1</td>\n",
              "      <td>519.0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.805518</td>\n",
              "      <td>1.056518</td>\n",
              "      <td>0.239507</td>\n",
              "      <td>0.318711</td>\n",
              "      <td>0.051836</td>\n",
              "      <td>0.775219</td>\n",
              "      <td>-1.169461</td>\n",
              "      <td>-0.319936</td>\n",
              "      <td>0.973596</td>\n",
              "      <td>1.300858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>522</th>\n",
              "      <td>64</td>\n",
              "      <td>0.7913</td>\n",
              "      <td>0</td>\n",
              "      <td>254.0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.217459</td>\n",
              "      <td>0.080498</td>\n",
              "      <td>-1.176566</td>\n",
              "      <td>1.217711</td>\n",
              "      <td>-1.050512</td>\n",
              "      <td>1.359610</td>\n",
              "      <td>-2.020466</td>\n",
              "      <td>0.376563</td>\n",
              "      <td>-0.632390</td>\n",
              "      <td>0.506706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>64</td>\n",
              "      <td>0.7913</td>\n",
              "      <td>1</td>\n",
              "      <td>49.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.004791</td>\n",
              "      <td>-0.452144</td>\n",
              "      <td>-0.676868</td>\n",
              "      <td>0.712657</td>\n",
              "      <td>-0.160630</td>\n",
              "      <td>-0.496352</td>\n",
              "      <td>0.470072</td>\n",
              "      <td>-0.928281</td>\n",
              "      <td>-0.390164</td>\n",
              "      <td>1.164984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>50</td>\n",
              "      <td>0.8880</td>\n",
              "      <td>0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.854834</td>\n",
              "      <td>-0.835060</td>\n",
              "      <td>-0.947755</td>\n",
              "      <td>-0.455384</td>\n",
              "      <td>-1.377887</td>\n",
              "      <td>1.115194</td>\n",
              "      <td>-0.854169</td>\n",
              "      <td>-0.730861</td>\n",
              "      <td>0.136779</td>\n",
              "      <td>-1.027946</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     years_to_birth  Tumor_purity  gender  ...  feature8  feature9  feature10\n",
              "0                44        0.7876       0  ... -0.560789  1.058499  -0.334538\n",
              "1                50        0.9850       1  ... -0.563669  0.241410  -0.530486\n",
              "2                59        0.7937       1  ...  1.033209  0.791622  -0.124257\n",
              "3                40        0.9850       0  ... -0.751569  0.046941  -2.149184\n",
              "4                61        0.9850       0  ... -1.417825  1.663926   1.207126\n",
              "..              ...           ...     ...  ...       ...       ...        ...\n",
              "520              78        0.6246       1  ...  0.263943  0.843129  -0.008105\n",
              "521              63        0.7034       1  ... -0.319936  0.973596   1.300858\n",
              "522              64        0.7913       0  ...  0.376563 -0.632390   0.506706\n",
              "523              64        0.7913       1  ... -0.928281 -0.390164   1.164984\n",
              "524              50        0.8880       0  ... -0.730861  0.136779  -1.027946\n",
              "\n",
              "[500 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBTRD6ttZhVt",
        "outputId": "cdc8ea60-b6f9-49d3-dbb5-926f02508617"
      },
      "source": [
        "finaldata[\"feature2\"].std()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.011554479598999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fN5P-250xca"
      },
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(finaldata,finaldata,test_size=0.25,random_state=123)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "ENrOJoXQIHF3",
        "outputId": "12c2b0d4-fcc9-429c-d14a-a1206227187b"
      },
      "source": [
        "x_train"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>years_to_birth</th>\n",
              "      <th>Tumor_purity</th>\n",
              "      <th>gender</th>\n",
              "      <th>overall_survival</th>\n",
              "      <th>status</th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>478</th>\n",
              "      <td>57</td>\n",
              "      <td>0.9068</td>\n",
              "      <td>1</td>\n",
              "      <td>482.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.589427</td>\n",
              "      <td>-1.076201</td>\n",
              "      <td>-0.376078</td>\n",
              "      <td>-1.075209</td>\n",
              "      <td>0.654092</td>\n",
              "      <td>-0.291043</td>\n",
              "      <td>0.157087</td>\n",
              "      <td>0.009405</td>\n",
              "      <td>-1.010715</td>\n",
              "      <td>0.895719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>76</td>\n",
              "      <td>0.8136</td>\n",
              "      <td>0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.279265</td>\n",
              "      <td>-0.116994</td>\n",
              "      <td>-0.418098</td>\n",
              "      <td>1.069188</td>\n",
              "      <td>1.457101</td>\n",
              "      <td>-0.250954</td>\n",
              "      <td>-0.411878</td>\n",
              "      <td>-1.297471</td>\n",
              "      <td>0.939263</td>\n",
              "      <td>0.355855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>68</td>\n",
              "      <td>0.8868</td>\n",
              "      <td>0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.024169</td>\n",
              "      <td>0.721367</td>\n",
              "      <td>0.696442</td>\n",
              "      <td>2.259001</td>\n",
              "      <td>-0.290628</td>\n",
              "      <td>-0.716103</td>\n",
              "      <td>-1.428476</td>\n",
              "      <td>-0.916195</td>\n",
              "      <td>1.865824</td>\n",
              "      <td>-1.568957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>34</td>\n",
              "      <td>0.8872</td>\n",
              "      <td>1</td>\n",
              "      <td>510.0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.464685</td>\n",
              "      <td>1.701223</td>\n",
              "      <td>-0.991760</td>\n",
              "      <td>-0.166580</td>\n",
              "      <td>1.010150</td>\n",
              "      <td>-0.217108</td>\n",
              "      <td>1.021365</td>\n",
              "      <td>-0.281113</td>\n",
              "      <td>-0.491579</td>\n",
              "      <td>0.005447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>72</td>\n",
              "      <td>0.9700</td>\n",
              "      <td>0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.306832</td>\n",
              "      <td>1.526117</td>\n",
              "      <td>-1.444299</td>\n",
              "      <td>0.033829</td>\n",
              "      <td>0.301292</td>\n",
              "      <td>-1.542278</td>\n",
              "      <td>1.984381</td>\n",
              "      <td>1.985131</td>\n",
              "      <td>-0.079316</td>\n",
              "      <td>0.314587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>64</td>\n",
              "      <td>0.3852</td>\n",
              "      <td>1</td>\n",
              "      <td>435.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.740543</td>\n",
              "      <td>2.412371</td>\n",
              "      <td>0.606821</td>\n",
              "      <td>0.684437</td>\n",
              "      <td>-0.080601</td>\n",
              "      <td>0.703440</td>\n",
              "      <td>-1.320848</td>\n",
              "      <td>-1.525122</td>\n",
              "      <td>0.773809</td>\n",
              "      <td>-0.114868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>66</td>\n",
              "      <td>0.8265</td>\n",
              "      <td>1</td>\n",
              "      <td>585.0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.613546</td>\n",
              "      <td>2.188905</td>\n",
              "      <td>-1.507603</td>\n",
              "      <td>0.317495</td>\n",
              "      <td>0.145366</td>\n",
              "      <td>-1.550206</td>\n",
              "      <td>0.396902</td>\n",
              "      <td>-0.378503</td>\n",
              "      <td>0.463955</td>\n",
              "      <td>-0.318677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334</th>\n",
              "      <td>74</td>\n",
              "      <td>0.9850</td>\n",
              "      <td>0</td>\n",
              "      <td>880.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.339775</td>\n",
              "      <td>1.561462</td>\n",
              "      <td>0.083016</td>\n",
              "      <td>-0.573434</td>\n",
              "      <td>-0.470242</td>\n",
              "      <td>1.664003</td>\n",
              "      <td>0.878496</td>\n",
              "      <td>-0.499127</td>\n",
              "      <td>1.101836</td>\n",
              "      <td>1.161442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>83</td>\n",
              "      <td>0.9180</td>\n",
              "      <td>1</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.677235</td>\n",
              "      <td>0.631615</td>\n",
              "      <td>-1.090022</td>\n",
              "      <td>-0.623382</td>\n",
              "      <td>-0.121123</td>\n",
              "      <td>0.996649</td>\n",
              "      <td>-0.861840</td>\n",
              "      <td>-0.471655</td>\n",
              "      <td>-0.501250</td>\n",
              "      <td>-0.532782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>83</td>\n",
              "      <td>0.9403</td>\n",
              "      <td>0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.981459</td>\n",
              "      <td>-1.676315</td>\n",
              "      <td>1.199109</td>\n",
              "      <td>1.474688</td>\n",
              "      <td>1.542080</td>\n",
              "      <td>0.088404</td>\n",
              "      <td>0.110281</td>\n",
              "      <td>-0.057780</td>\n",
              "      <td>-1.122211</td>\n",
              "      <td>-0.816280</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>375 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     years_to_birth  Tumor_purity  gender  ...  feature8  feature9  feature10\n",
              "478              57        0.9068       1  ...  0.009405 -1.010715   0.895719\n",
              "402              76        0.8136       0  ... -1.297471  0.939263   0.355855\n",
              "304              68        0.8868       0  ... -0.916195  1.865824  -1.568957\n",
              "439              34        0.8872       1  ... -0.281113 -0.491579   0.005447\n",
              "390              72        0.9700       0  ...  1.985131 -0.079316   0.314587\n",
              "..              ...           ...     ...  ...       ...       ...        ...\n",
              "99               64        0.3852       1  ... -1.525122  0.773809  -0.114868\n",
              "499              66        0.8265       1  ... -0.378503  0.463955  -0.318677\n",
              "334              74        0.9850       0  ... -0.499127  1.101836   1.161442\n",
              "399              83        0.9180       1  ... -0.471655 -0.501250  -0.532782\n",
              "380              83        0.9403       0  ... -0.057780 -1.122211  -0.816280\n",
              "\n",
              "[375 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmoLRxqG09GP",
        "outputId": "276f814f-f30e-47d1-bd48-b4b085a3c93f"
      },
      "source": [
        "!pip install lifelines"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lifelines in /usr/local/lib/python3.7/dist-packages (0.25.11)\n",
            "Requirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from lifelines) (1.3)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.7/dist-packages (from lifelines) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from lifelines) (1.1.5)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from lifelines) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from lifelines) (1.19.5)\n",
            "Requirement already satisfied: formulaic<0.3,>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from lifelines) (0.2.3)\n",
            "Requirement already satisfied: autograd-gamma>=0.3 in /usr/local/lib/python3.7/dist-packages (from lifelines) (0.5.0)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->lifelines) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines) (1.3.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->lifelines) (2018.9)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.7/dist-packages (from formulaic<0.3,>=0.2.2->lifelines) (1.12.1)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from formulaic<0.3,>=0.2.2->lifelines) (0.8.1)\n",
            "Requirement already satisfied: interface-meta>=1.2 in /usr/local/lib/python3.7/dist-packages (from formulaic<0.3,>=0.2.2->lifelines) (1.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.0->lifelines) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHOW2fFU1E2F"
      },
      "source": [
        "from lifelines import WeibullAFTFitter\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xhhuwe2c00WS"
      },
      "source": [
        "aft=WeibullAFTFitter()\n",
        "aft=aft.fit(x_train, duration_col=\"overall_survival\", event_col=\"status\")"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFGuynszjxH3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVzSzCY11G-v"
      },
      "source": [
        "sum=pd.DataFrame(aft.summary)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "id": "qGwI0HXLD2LM",
        "outputId": "070dea6b-8877-4ae1-89f4-12cae1cd27f4"
      },
      "source": [
        "sum"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>coef</th>\n",
              "      <th>exp(coef)</th>\n",
              "      <th>se(coef)</th>\n",
              "      <th>coef lower 95%</th>\n",
              "      <th>coef upper 95%</th>\n",
              "      <th>exp(coef) lower 95%</th>\n",
              "      <th>exp(coef) upper 95%</th>\n",
              "      <th>z</th>\n",
              "      <th>p</th>\n",
              "      <th>-log2(p)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>param</th>\n",
              "      <th>covariate</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"14\" valign=\"top\">lambda_</th>\n",
              "      <th>Tumor_purity</th>\n",
              "      <td>0.673492</td>\n",
              "      <td>1.961073</td>\n",
              "      <td>0.231233</td>\n",
              "      <td>0.220284</td>\n",
              "      <td>1.126700</td>\n",
              "      <td>1.246431</td>\n",
              "      <td>3.085457</td>\n",
              "      <td>2.912615</td>\n",
              "      <td>3.584161e-03</td>\n",
              "      <td>8.124149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature1</th>\n",
              "      <td>-0.062836</td>\n",
              "      <td>0.939097</td>\n",
              "      <td>0.044540</td>\n",
              "      <td>-0.150134</td>\n",
              "      <td>0.024461</td>\n",
              "      <td>0.860593</td>\n",
              "      <td>1.024762</td>\n",
              "      <td>-1.410779</td>\n",
              "      <td>1.583097e-01</td>\n",
              "      <td>2.659179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature10</th>\n",
              "      <td>-0.092050</td>\n",
              "      <td>0.912059</td>\n",
              "      <td>0.036717</td>\n",
              "      <td>-0.164014</td>\n",
              "      <td>-0.020087</td>\n",
              "      <td>0.848730</td>\n",
              "      <td>0.980113</td>\n",
              "      <td>-2.507048</td>\n",
              "      <td>1.217442e-02</td>\n",
              "      <td>6.360003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature2</th>\n",
              "      <td>-0.017480</td>\n",
              "      <td>0.982672</td>\n",
              "      <td>0.044228</td>\n",
              "      <td>-0.104165</td>\n",
              "      <td>0.069205</td>\n",
              "      <td>0.901077</td>\n",
              "      <td>1.071656</td>\n",
              "      <td>-0.395223</td>\n",
              "      <td>6.926785e-01</td>\n",
              "      <td>0.529742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature3</th>\n",
              "      <td>-0.082599</td>\n",
              "      <td>0.920720</td>\n",
              "      <td>0.043035</td>\n",
              "      <td>-0.166945</td>\n",
              "      <td>0.001747</td>\n",
              "      <td>0.846246</td>\n",
              "      <td>1.001749</td>\n",
              "      <td>-1.919362</td>\n",
              "      <td>5.493858e-02</td>\n",
              "      <td>4.186037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature4</th>\n",
              "      <td>-0.061286</td>\n",
              "      <td>0.940554</td>\n",
              "      <td>0.044185</td>\n",
              "      <td>-0.147887</td>\n",
              "      <td>0.025315</td>\n",
              "      <td>0.862529</td>\n",
              "      <td>1.025638</td>\n",
              "      <td>-1.387040</td>\n",
              "      <td>1.654295e-01</td>\n",
              "      <td>2.595712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature5</th>\n",
              "      <td>-0.037102</td>\n",
              "      <td>0.963578</td>\n",
              "      <td>0.040997</td>\n",
              "      <td>-0.117453</td>\n",
              "      <td>0.043250</td>\n",
              "      <td>0.889182</td>\n",
              "      <td>1.044199</td>\n",
              "      <td>-0.904995</td>\n",
              "      <td>3.654681e-01</td>\n",
              "      <td>1.452183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature6</th>\n",
              "      <td>-0.020404</td>\n",
              "      <td>0.979803</td>\n",
              "      <td>0.045332</td>\n",
              "      <td>-0.109253</td>\n",
              "      <td>0.068445</td>\n",
              "      <td>0.896504</td>\n",
              "      <td>1.070841</td>\n",
              "      <td>-0.450107</td>\n",
              "      <td>6.526336e-01</td>\n",
              "      <td>0.615655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature7</th>\n",
              "      <td>0.025933</td>\n",
              "      <td>1.026273</td>\n",
              "      <td>0.042086</td>\n",
              "      <td>-0.056554</td>\n",
              "      <td>0.108421</td>\n",
              "      <td>0.945016</td>\n",
              "      <td>1.114516</td>\n",
              "      <td>0.616198</td>\n",
              "      <td>5.377636e-01</td>\n",
              "      <td>0.894956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature8</th>\n",
              "      <td>0.068050</td>\n",
              "      <td>1.070419</td>\n",
              "      <td>0.045394</td>\n",
              "      <td>-0.020920</td>\n",
              "      <td>0.157020</td>\n",
              "      <td>0.979297</td>\n",
              "      <td>1.170018</td>\n",
              "      <td>1.499107</td>\n",
              "      <td>1.338458e-01</td>\n",
              "      <td>2.901356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature9</th>\n",
              "      <td>0.010329</td>\n",
              "      <td>1.010382</td>\n",
              "      <td>0.040114</td>\n",
              "      <td>-0.068293</td>\n",
              "      <td>0.088950</td>\n",
              "      <td>0.933987</td>\n",
              "      <td>1.093026</td>\n",
              "      <td>0.257481</td>\n",
              "      <td>7.968073e-01</td>\n",
              "      <td>0.327697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender</th>\n",
              "      <td>-0.006339</td>\n",
              "      <td>0.993681</td>\n",
              "      <td>0.087256</td>\n",
              "      <td>-0.177358</td>\n",
              "      <td>0.164680</td>\n",
              "      <td>0.837480</td>\n",
              "      <td>1.179016</td>\n",
              "      <td>-0.072648</td>\n",
              "      <td>9.420863e-01</td>\n",
              "      <td>0.086069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>years_to_birth</th>\n",
              "      <td>-0.025480</td>\n",
              "      <td>0.974842</td>\n",
              "      <td>0.003112</td>\n",
              "      <td>-0.031580</td>\n",
              "      <td>-0.019380</td>\n",
              "      <td>0.968914</td>\n",
              "      <td>0.980807</td>\n",
              "      <td>-8.186636</td>\n",
              "      <td>2.686283e-16</td>\n",
              "      <td>51.725238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Intercept</th>\n",
              "      <td>7.320534</td>\n",
              "      <td>1511.009936</td>\n",
              "      <td>0.289806</td>\n",
              "      <td>6.752525</td>\n",
              "      <td>7.888542</td>\n",
              "      <td>856.218108</td>\n",
              "      <td>2666.553074</td>\n",
              "      <td>25.260158</td>\n",
              "      <td>8.759285e-141</td>\n",
              "      <td>465.261048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rho_</th>\n",
              "      <th>Intercept</th>\n",
              "      <td>0.303529</td>\n",
              "      <td>1.354631</td>\n",
              "      <td>0.041415</td>\n",
              "      <td>0.222358</td>\n",
              "      <td>0.384700</td>\n",
              "      <td>1.249018</td>\n",
              "      <td>1.469174</td>\n",
              "      <td>7.329016</td>\n",
              "      <td>2.318483e-13</td>\n",
              "      <td>41.971884</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            coef    exp(coef)  ...              p    -log2(p)\n",
              "param   covariate                              ...                           \n",
              "lambda_ Tumor_purity    0.673492     1.961073  ...   3.584161e-03    8.124149\n",
              "        feature1       -0.062836     0.939097  ...   1.583097e-01    2.659179\n",
              "        feature10      -0.092050     0.912059  ...   1.217442e-02    6.360003\n",
              "        feature2       -0.017480     0.982672  ...   6.926785e-01    0.529742\n",
              "        feature3       -0.082599     0.920720  ...   5.493858e-02    4.186037\n",
              "        feature4       -0.061286     0.940554  ...   1.654295e-01    2.595712\n",
              "        feature5       -0.037102     0.963578  ...   3.654681e-01    1.452183\n",
              "        feature6       -0.020404     0.979803  ...   6.526336e-01    0.615655\n",
              "        feature7        0.025933     1.026273  ...   5.377636e-01    0.894956\n",
              "        feature8        0.068050     1.070419  ...   1.338458e-01    2.901356\n",
              "        feature9        0.010329     1.010382  ...   7.968073e-01    0.327697\n",
              "        gender         -0.006339     0.993681  ...   9.420863e-01    0.086069\n",
              "        years_to_birth -0.025480     0.974842  ...   2.686283e-16   51.725238\n",
              "        Intercept       7.320534  1511.009936  ...  8.759285e-141  465.261048\n",
              "rho_    Intercept       0.303529     1.354631  ...   2.318483e-13   41.971884\n",
              "\n",
              "[15 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGVr7spH1Rd9",
        "outputId": "7df5ef74-8cd2-46f8-f277-690184007a6e"
      },
      "source": [
        "p=aft.predict_expectation(x_test)\n",
        "concordance_index(x_test[\"overall_survival\"],p,x_test[\"status\"])"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6401544401544401"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        },
        "id": "nGMSESdnk91k",
        "outputId": "2488742b-77c4-43cb-cdb8-2950876350f0"
      },
      "source": [
        "aft.print_summary()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/latex": "\\begin{tabular}{llrrrrrrrrrr}\n\\toprule\n     &           &  coef &  exp(coef) &  se(coef) &  coef lower 95\\% &  coef upper 95\\% &  exp(coef) lower 95\\% &  exp(coef) upper 95\\% &     z &    p &  -log2(p) \\\\\nparam & covariate &       &            &           &                 &                 &                      &                      &       &      &           \\\\\n\\midrule\nlambda\\_ & Tumor\\_purity &  0.67 &       1.96 &      0.23 &            0.22 &            1.13 &                 1.25 &                 3.09 &  2.91 & 0.00 &      8.12 \\\\\n     & feature1 & -0.06 &       0.94 &      0.04 &           -0.15 &            0.02 &                 0.86 &                 1.02 & -1.41 & 0.16 &      2.66 \\\\\n     & feature10 & -0.09 &       0.91 &      0.04 &           -0.16 &           -0.02 &                 0.85 &                 0.98 & -2.51 & 0.01 &      6.36 \\\\\n     & feature2 & -0.02 &       0.98 &      0.04 &           -0.10 &            0.07 &                 0.90 &                 1.07 & -0.40 & 0.69 &      0.53 \\\\\n     & feature3 & -0.08 &       0.92 &      0.04 &           -0.17 &            0.00 &                 0.85 &                 1.00 & -1.92 & 0.05 &      4.19 \\\\\n     & feature4 & -0.06 &       0.94 &      0.04 &           -0.15 &            0.03 &                 0.86 &                 1.03 & -1.39 & 0.17 &      2.60 \\\\\n     & feature5 & -0.04 &       0.96 &      0.04 &           -0.12 &            0.04 &                 0.89 &                 1.04 & -0.90 & 0.37 &      1.45 \\\\\n     & feature6 & -0.02 &       0.98 &      0.05 &           -0.11 &            0.07 &                 0.90 &                 1.07 & -0.45 & 0.65 &      0.62 \\\\\n     & feature7 &  0.03 &       1.03 &      0.04 &           -0.06 &            0.11 &                 0.95 &                 1.11 &  0.62 & 0.54 &      0.89 \\\\\n     & feature8 &  0.07 &       1.07 &      0.05 &           -0.02 &            0.16 &                 0.98 &                 1.17 &  1.50 & 0.13 &      2.90 \\\\\n     & feature9 &  0.01 &       1.01 &      0.04 &           -0.07 &            0.09 &                 0.93 &                 1.09 &  0.26 & 0.80 &      0.33 \\\\\n     & gender & -0.01 &       0.99 &      0.09 &           -0.18 &            0.16 &                 0.84 &                 1.18 & -0.07 & 0.94 &      0.09 \\\\\n     & years\\_to\\_birth & -0.03 &       0.97 &      0.00 &           -0.03 &           -0.02 &                 0.97 &                 0.98 & -8.19 & 0.00 &     51.73 \\\\\n     & Intercept &  7.32 &    1511.01 &      0.29 &            6.75 &            7.89 &               856.22 &              2666.55 & 25.26 & 0.00 &    465.26 \\\\\nrho\\_ & Intercept &  0.30 &       1.35 &      0.04 &            0.22 &            0.38 &                 1.25 &                 1.47 &  7.33 & 0.00 &     41.97 \\\\\n\\bottomrule\n\\end{tabular}\n",
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>model</th>\n",
              "      <td>lifelines.WeibullAFTFitter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>duration col</th>\n",
              "      <td>'overall_survival'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>event col</th>\n",
              "      <td>'status'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>number of observations</th>\n",
              "      <td>375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>number of events observed</th>\n",
              "      <td>324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>log-likelihood</th>\n",
              "      <td>-2350.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time fit was run</th>\n",
              "      <td>2021-07-01 22:11:43 UTC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th style=\"min-width: 12px;\"></th>\n",
              "      <th style=\"min-width: 12px;\"></th>\n",
              "      <th style=\"min-width: 12px;\">coef</th>\n",
              "      <th style=\"min-width: 12px;\">exp(coef)</th>\n",
              "      <th style=\"min-width: 12px;\">se(coef)</th>\n",
              "      <th style=\"min-width: 12px;\">coef lower 95%</th>\n",
              "      <th style=\"min-width: 12px;\">coef upper 95%</th>\n",
              "      <th style=\"min-width: 12px;\">exp(coef) lower 95%</th>\n",
              "      <th style=\"min-width: 12px;\">exp(coef) upper 95%</th>\n",
              "      <th style=\"min-width: 12px;\">z</th>\n",
              "      <th style=\"min-width: 12px;\">p</th>\n",
              "      <th style=\"min-width: 12px;\">-log2(p)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"14\" valign=\"top\">lambda_</th>\n",
              "      <th>Tumor_purity</th>\n",
              "      <td>0.67</td>\n",
              "      <td>1.96</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.22</td>\n",
              "      <td>1.13</td>\n",
              "      <td>1.25</td>\n",
              "      <td>3.09</td>\n",
              "      <td>2.91</td>\n",
              "      <td>&lt;0.005</td>\n",
              "      <td>8.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature1</th>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.86</td>\n",
              "      <td>1.02</td>\n",
              "      <td>-1.41</td>\n",
              "      <td>0.16</td>\n",
              "      <td>2.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature10</th>\n",
              "      <td>-0.09</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.16</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.98</td>\n",
              "      <td>-2.51</td>\n",
              "      <td>0.01</td>\n",
              "      <td>6.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature2</th>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.07</td>\n",
              "      <td>-0.40</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature3</th>\n",
              "      <td>-0.08</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.17</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.85</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-1.92</td>\n",
              "      <td>0.05</td>\n",
              "      <td>4.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature4</th>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.86</td>\n",
              "      <td>1.03</td>\n",
              "      <td>-1.39</td>\n",
              "      <td>0.17</td>\n",
              "      <td>2.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature5</th>\n",
              "      <td>-0.04</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.89</td>\n",
              "      <td>1.04</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>0.37</td>\n",
              "      <td>1.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature6</th>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.05</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.07</td>\n",
              "      <td>-0.45</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature7</th>\n",
              "      <td>0.03</td>\n",
              "      <td>1.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.95</td>\n",
              "      <td>1.11</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature8</th>\n",
              "      <td>0.07</td>\n",
              "      <td>1.07</td>\n",
              "      <td>0.05</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.98</td>\n",
              "      <td>1.17</td>\n",
              "      <td>1.50</td>\n",
              "      <td>0.13</td>\n",
              "      <td>2.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature9</th>\n",
              "      <td>0.01</td>\n",
              "      <td>1.01</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.93</td>\n",
              "      <td>1.09</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender</th>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.09</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.84</td>\n",
              "      <td>1.18</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>years_to_birth</th>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.98</td>\n",
              "      <td>-8.19</td>\n",
              "      <td>&lt;0.005</td>\n",
              "      <td>51.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Intercept</th>\n",
              "      <td>7.32</td>\n",
              "      <td>1511.01</td>\n",
              "      <td>0.29</td>\n",
              "      <td>6.75</td>\n",
              "      <td>7.89</td>\n",
              "      <td>856.22</td>\n",
              "      <td>2666.55</td>\n",
              "      <td>25.26</td>\n",
              "      <td>&lt;0.005</td>\n",
              "      <td>465.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rho_</th>\n",
              "      <th>Intercept</th>\n",
              "      <td>0.30</td>\n",
              "      <td>1.35</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.38</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.47</td>\n",
              "      <td>7.33</td>\n",
              "      <td>&lt;0.005</td>\n",
              "      <td>41.97</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><br><div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Concordance</th>\n",
              "      <td>0.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AIC</th>\n",
              "      <td>4730.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>log-likelihood ratio test</th>\n",
              "      <td>92.63 on 13 df</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-log2(p) of ll-ratio test</th>\n",
              "      <td>44.38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "<lifelines.WeibullAFTFitter: fitted with 375 total observations, 51 right-censored observations>\n",
              "             duration col = 'overall_survival'\n",
              "                event col = 'status'\n",
              "   number of observations = 375\n",
              "number of events observed = 324\n",
              "           log-likelihood = -2350.49\n",
              "         time fit was run = 2021-07-01 22:11:43 UTC\n",
              "\n",
              "---\n",
              "                         coef  exp(coef)   se(coef)   coef lower 95%   coef upper 95%  exp(coef) lower 95%  exp(coef) upper 95%\n",
              "param   covariate                                                                                                              \n",
              "lambda_ Tumor_purity     0.67       1.96       0.23             0.22             1.13                 1.25                 3.09\n",
              "        feature1        -0.06       0.94       0.04            -0.15             0.02                 0.86                 1.02\n",
              "        feature10       -0.09       0.91       0.04            -0.16            -0.02                 0.85                 0.98\n",
              "        feature2        -0.02       0.98       0.04            -0.10             0.07                 0.90                 1.07\n",
              "        feature3        -0.08       0.92       0.04            -0.17             0.00                 0.85                 1.00\n",
              "        feature4        -0.06       0.94       0.04            -0.15             0.03                 0.86                 1.03\n",
              "        feature5        -0.04       0.96       0.04            -0.12             0.04                 0.89                 1.04\n",
              "        feature6        -0.02       0.98       0.05            -0.11             0.07                 0.90                 1.07\n",
              "        feature7         0.03       1.03       0.04            -0.06             0.11                 0.95                 1.11\n",
              "        feature8         0.07       1.07       0.05            -0.02             0.16                 0.98                 1.17\n",
              "        feature9         0.01       1.01       0.04            -0.07             0.09                 0.93                 1.09\n",
              "        gender          -0.01       0.99       0.09            -0.18             0.16                 0.84                 1.18\n",
              "        years_to_birth  -0.03       0.97       0.00            -0.03            -0.02                 0.97                 0.98\n",
              "        Intercept        7.32    1511.01       0.29             6.75             7.89               856.22              2666.55\n",
              "rho_    Intercept        0.30       1.35       0.04             0.22             0.38                 1.25                 1.47\n",
              "\n",
              "                           z      p   -log2(p)\n",
              "param   covariate                             \n",
              "lambda_ Tumor_purity    2.91 <0.005       8.12\n",
              "        feature1       -1.41   0.16       2.66\n",
              "        feature10      -2.51   0.01       6.36\n",
              "        feature2       -0.40   0.69       0.53\n",
              "        feature3       -1.92   0.05       4.19\n",
              "        feature4       -1.39   0.17       2.60\n",
              "        feature5       -0.90   0.37       1.45\n",
              "        feature6       -0.45   0.65       0.62\n",
              "        feature7        0.62   0.54       0.89\n",
              "        feature8        1.50   0.13       2.90\n",
              "        feature9        0.26   0.80       0.33\n",
              "        gender         -0.07   0.94       0.09\n",
              "        years_to_birth -8.19 <0.005      51.73\n",
              "        Intercept      25.26 <0.005     465.26\n",
              "rho_    Intercept       7.33 <0.005      41.97\n",
              "---\n",
              "Concordance = 0.63\n",
              "AIC = 4730.98\n",
              "log-likelihood ratio test = 92.63 on 13 df\n",
              "-log2(p) of ll-ratio test = 44.38"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oTgkQUJ4vkd"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBAJMvvw4imV"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B08x1_kD4jGB"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3-LkwTfterz",
        "outputId": "ff878c82-9506-44d7-ad61-aab7351b4a64"
      },
      "source": [
        "b=decoder.get_weights()\n",
        "len(b[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    }
  ]
}